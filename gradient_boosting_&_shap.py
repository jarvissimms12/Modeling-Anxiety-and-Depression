# -*- coding: utf-8 -*-
"""Gradient Boosting & SHAP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cD9RvKJs_zyBHkAi1XGNgVEIGm7iO2MB
"""

import os
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')
file_path = "/content/drive/MyDrive/Depression Professional Dataset.csv"
df = pd.read_csv(file_path)
# Show basic information and preview of the dataset
df.info(), df.head()

# Check for null values
null_summary = df.isnull().sum()
null_summary[null_summary > 0]

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import GradientBoostingClassifier
import shap
import matplotlib.pyplot as plt

##        SHAP Graph          ##

# Label encode categorical features
df_encoded = df.copy()
label_encoders = {}
for col in df_encoded.select_dtypes(include='object').columns:
    le = LabelEncoder()
    df_encoded[col] = le.fit_transform(df_encoded[col])
    label_encoders[col] = le

# Define X and y
X = df_encoded.drop("Depression", axis=1)
y = df_encoded["Depression"]

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = GradientBoostingClassifier(random_state=42)
model.fit(X_train, y_train)

# SHAP explanation
explainer = shap.Explainer(model, X_train)
shap_values = explainer(X_test)  # Use full test set

# Plot
shap.summary_plot(shap_values, X_test, plot_type="bar")

X=df.drop(["Depression"],axis=1)
y=df["Depression"]
y=pd.DataFrame(y)

scaler = StandardScaler(copy=True, with_mean=True, with_std=True)
X = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44, shuffle =True)

lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)
lr_y_pred = lr_model.predict(X_test)
lr_accuracy = accuracy_score(y_test, lr_y_pred)
print(f"Logistic Regression Accuracy: {lr_accuracy:.2f}")

print(classification_report(y_test, lr_y_pred))

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import classification_report
import shap

# Copy of dataframe for encoding
df_encoded = df.copy()

# Encode categorical variables
label_encoders = {}
for col in df_encoded.select_dtypes(include='object').columns:
    le = LabelEncoder()
    df_encoded[col] = le.fit_transform(df_encoded[col])
    label_encoders[col] = le

# Define features and target
X = df_encoded.drop("Depression", axis=1)
y = df_encoded["Depression"]

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Gradient Boosting model
gb_model = GradientBoostingClassifier(random_state=42)
gb_model.fit(X_train, y_train)

# Predict and evaluate
y_pred = gb_model.predict(X_test)
report = classification_report(y_test, y_pred, output_dict=True)

report

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import shap

# Copy of dataframe for encoding
df_encoded = df.copy()

# Encode categorical variables
label_encoders = {}
for col in df_encoded.select_dtypes(include='object').columns:
    le = LabelEncoder()
    df_encoded[col] = le.fit_transform(df_encoded[col])
    label_encoders[col] = le

# Define features and target
X = df_encoded.drop("Depression", axis=1)
y = df_encoded["Depression"]

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)

# Train Gradient Boosting model
gb_model = GradientBoostingClassifier(random_state=40)
gb_model.fit(X_train, y_train)

# Predict and evaluate
y_pred = gb_model.predict(X_test)
report = classification_report(y_test, y_pred, output_dict=True)

report